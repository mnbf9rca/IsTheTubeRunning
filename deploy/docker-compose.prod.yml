# Production Docker Compose for IsTheTubeRunning
# Domain: isthetube.cynexia.com
#
# Architecture:
#   - HTTP/HTTPS ingress via Cloudflare Tunnel (no published ports)
#   - SSH access via traditional networking (port 22, UFW + fail2ban protected)
#
# Prerequisites:
#   - DOTENV_KEY environment variable set on host
#   - CLOUDFLARE_TUNNEL_TOKEN environment variable set on host
#   - .env.vault file present in backend/ directory
#   - nginx.conf mounted from docker/nginx/
#   - Cloudflare Tunnel configured in Cloudflare Zero Trust dashboard
#
# Usage:
#   DOTENV_KEY="dotenv://..." CLOUDFLARE_TUNNEL_TOKEN="eyJ..." docker-compose -f docker-compose.prod.yml up -d
#
# Health checks:
#   docker-compose -f docker-compose.prod.yml ps
#   ./docker/scripts/health-check.sh

services:
  # PostgreSQL Database
  postgres:
    image: postgres:18
    container_name: isthetube-postgres-prod
    restart: unless-stopped
    env_file:
      - /home/deployuser/.env.secrets
    # POSTGRES_DB, POSTGRES_USER, and POSTGRES_PASSWORD all loaded from env_file
    # All three are extracted from DATABASE_URL in .env.vault for consistency
    volumes:
      - postgres_data:/var/lib/postgresql  # Match PostgreSQL 18+ pattern (same as dev)
    healthcheck:
      test: ["CMD-SHELL", "pg_isready"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 1G
    networks:
      - app-network

  # Redis Cache & Queue
  redis:
    image: redis:8.2.1-alpine
    container_name: isthetube-redis-prod
    restart: unless-stopped
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 5s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - app-network

  # Database Migrations (runs once before app starts)
  migrations:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: isthetube-migrations-prod
    env_file:
      - /home/deployuser/.env.secrets
    # DOTENV_KEY loaded from env_file above - no need to override here
    depends_on:
      postgres:
        condition: service_healthy
    command: alembic upgrade head
    restart: "no"  # Only run once, don't restart on failure
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M

  # FastAPI Backend
  backend:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: isthetube-backend-prod
    restart: unless-stopped
    env_file:
      - /home/deployuser/.env.secrets
    environment:
      # DOTENV_KEY loaded from env_file above
      OTEL_SERVICE_NAME: isthetuberunning-api
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      - app-network

  # Celery Worker
  celery-worker:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: isthetube-celery-worker-prod
    restart: unless-stopped
    command: /app/.venv/bin/celery -A app.celery.app worker --loglevel=info --concurrency=2
    env_file:
      - /home/deployuser/.env.secrets
    environment:
      # DOTENV_KEY loaded from env_file above
      OTEL_SERVICE_NAME: isthetuberunning-worker
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      migrations:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          cpus: '1.0'
          memory: 1G
        reservations:
          cpus: '0.5'
          memory: 512M
    networks:
      - app-network

  # Celery Beat Scheduler
  celery-beat:
    build:
      context: ../backend
      dockerfile: Dockerfile
    container_name: isthetube-celery-beat-prod
    restart: unless-stopped
    command: /app/.venv/bin/celery -A app.celery.app beat --loglevel=info
    env_file:
      - /home/deployuser/.env.secrets
    environment:
      # DOTENV_KEY loaded from env_file above
      OTEL_SERVICE_NAME: isthetuberunning-beat
    depends_on:
      redis:
        condition: service_started
      migrations:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M
        reservations:
          cpus: '0.1'
          memory: 128M
    networks:
      - app-network

  # Frontend Builder (init container - builds assets, populates volume, exits)
  # Architecture: This container builds frontend assets during Docker build, then populates
  # the frontend_static volume at runtime and exits. Nginx serves files from this volume.
  # Benefits: (1) No duplicate serving (2) Nginx starts immediately (3) Clean deployments
  #
  # IMPORTANT: To deploy frontend updates, use --force-recreate:
  #   docker compose -f deploy/docker-compose.prod.yml up -d --build --force-recreate frontend nginx
  frontend:
    build:
      context: ../frontend
      dockerfile: Dockerfile
    container_name: isthetube-frontend-prod
    restart: "no"  # Init container - run once then exit (use --force-recreate to run again)
    # Port not exposed - nginx handles all external traffic
    volumes:
      - frontend_static:/www
      # No config mount needed - config.json contains all environments
      # and auto-detects based on hostname (isthetube.cynexia.com → production)
    # Override CMD to just copy files and exit (no need to run httpd)
    command: sh -c "echo 'Frontend assets built and ready in volume' && sleep 1"
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M
        reservations:
          cpus: '0.25'
          memory: 256M
    networks:
      - app-network

  # Nginx Reverse Proxy (serves frontend + proxies backend API)
  # NOTE: No ports published - Cloudflare Tunnel provides ingress (see cloudflared service below)
  # This eliminates Docker's iptables bypass of UFW firewall rules (see ADR 01)
  nginx:
    image: nginx:alpine
    container_name: isthetube-nginx-prod
    restart: unless-stopped
    # ports: REMOVED - Traffic ingresses via Cloudflare Tunnel instead of direct port publishing
    #   This resolves Docker/UFW firewall incompatibility where Docker bypasses UFW rules.
    #   See: https://docs.docker.com/engine/network/packet-filtering-firewalls/
    #   Port 443 not needed - Cloudflare handles TLS termination per ADR 01
    volumes:
      - ../docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - frontend_static:/usr/share/nginx/html:ro
    depends_on:
      frontend:
        condition: service_completed_successfully  # Wait for init container to populate volume
      # No backend dependency - static files should serve immediately
      # Backend health is checked via nginx proxy_pass, which handles failures gracefully
    healthcheck:
      test: ["CMD", "wget", "-q", "-O", "/dev/null", "http://localhost/nginx-health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 15s
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 256M
        reservations:
          cpus: '0.25'
          memory: 128M
    networks:
      - app-network

  # Cloudflare Tunnel (Zero Trust ingress)
  # Provides secure ingress without publishing ports, eliminating Docker/UFW firewall bypass issue
  # Traffic flow: Internet → Cloudflare Edge → Encrypted Tunnel → nginx container
  # SSH traffic continues to use traditional networking (port 22, protected by UFW + fail2ban)
  cloudflared:
    image: cloudflare/cloudflared:latest
    container_name: isthetube-cloudflared-prod
    restart: unless-stopped
    command: tunnel run
    env_file:
      - /home/deployuser/.env.secrets
    # TUNNEL_TOKEN loaded from env_file (written as both CLOUDFLARE_TUNNEL_TOKEN and TUNNEL_TOKEN)
    # No depends_on - tunnel should establish connection independently of application health
    # This allows Cloudflare to return 502 Bad Gateway when backend fails (better for troubleshooting)
    networks:
      - app-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
        reservations:
          cpus: '0.1'
          memory: 64M

volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  frontend_static:
    driver: local

networks:
  app-network:
    driver: bridge
